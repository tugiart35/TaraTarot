#!/usr/bin/env python3
"""
SÄ±rpÃ§a (Latin) Batch Test - EN â†’ SR (Latin)
en-sla modeli ile >>srp_Latn<< prefix kullanarak
"""

import json
from pathlib import Path
from transformers import MarianTokenizer, MarianMTModel
import torch
import re
from typing import Dict, Tuple

# Placeholder koruma
PLACEHOLDER_RE = re.compile(r"(\{\{.*?\}\}|%\w|%\{.*?\}|\{[0-9]+\}|\{[a-zA-Z_][a-zA-Z0-9_]*\}|<[^>]+>)")

def protect_placeholders(text: str) -> Tuple[str, Dict[str, str]]:
    tokens = {}
    def replace_placeholder(match):
        key = f"__PH_{len(tokens)}__"
        tokens[key] = match.group(0)
        return key
    protected = PLACEHOLDER_RE.sub(replace_placeholder, text)
    return protected, tokens

def restore_placeholders(text: str, tokens: Dict[str, str]) -> str:
    for placeholder_key, original_value in tokens.items():
        text = text.replace(placeholder_key, original_value)
    return text

def collect_strings(obj, path=()):
    out = []
    if isinstance(obj, dict):
        for k, v in obj.items():
            out += collect_strings(v, path + (k,))
    elif isinstance(obj, list):
        for i, v in enumerate(obj):
            out += collect_strings(v, path + (i,))
    elif isinstance(obj, str):
        out.append((path, obj))
    return out

def set_by_path(obj, path, value):
    cur = obj
    for p in path[:-1]:
        cur = cur[p]
    cur[path[-1]] = value

def create_empty_structure(obj):
    if isinstance(obj, dict):
        return {k: create_empty_structure(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [create_empty_structure(item) for item in obj]
    elif isinstance(obj, str):
        return ""
    else:
        return obj

def has_cyrillic(text):
    """Kiril alfabesi var mÄ± kontrol et"""
    cyrillic_pattern = re.compile(r'[Ð°-ÑÐ-Ð¯Ñ‘Ð]')
    return bool(cyrillic_pattern.search(text))

print("="*70)
print("ðŸ§ª SIRPÃ‡A (LATIN) BATCH TEST - EN â†’ SR")
print("="*70)
print("ðŸ“¦ Model: Helsinki-NLP/opus-mt-en-sla")
print("ðŸ”¤ Prefix: >>srp_Latn<<")
print("="*70)

# Ä°ngilizce test verisi (batch_01_en.json'dan)
print("\nðŸ“– Test iÃ§in Ä°ngilizce veri hazÄ±rlanÄ±yor...")

test_data = {
    "dashboard": {
        "errors": {
            "statsLoadFailed": "Could not load statistics",
            "creditRefreshFailed": "Credit balance could not be renewed",
            "loadError": "An error occurred while loading Dashboard components."
        },
        "sections": {
            "welcome": "Welcome",
            "statistics": "Statistics",
            "creditPackages": "Credit Packages",
            "profileManagement": "Profile Management"
        },
        "time": {
            "day": "day",
            "days": "days"
        }
    }
}

all_strings = collect_strings(test_data)
test_strings = all_strings[:10]  # Ä°lk 10 string

print(f"âœ… {len(all_strings)} string hazÄ±r")
print(f"ðŸ§ª Ä°lk 10 string test edilecek\n")

# en-sla modeli yÃ¼kle
print("ðŸ“¦ MarianMT en-sla (Slavic) model yÃ¼kleniyor...")
tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-sla')
model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-sla')
print("âœ… Model hazÄ±r!\n")

# BoÅŸ template
template = create_empty_structure(test_data)

print("="*70)
print("Ä°NGÄ°LÄ°ZCE â†’ SIRPÃ‡A (LATIN) Ã‡EVÄ°RÄ° TESTÄ°")
print("="*70)

cyrillic_found = []

for idx, (path, original_text) in enumerate(test_strings, 1):
    path_str = " â†’ ".join(str(p) for p in path)
    print(f"\n{idx}/10: {path_str}")
    print(f"  ðŸ‡¬ðŸ‡§ EN: {original_text}")
    
    # Placeholder koru
    protected_text, placeholders = protect_placeholders(original_text)
    
    # âœ¨ SIRPÃ‡A LATIN Ä°Ã‡Ä°N PREFIX EKLE
    protected_text = f">>srp_Latn<< {protected_text}"
    
    # Ã‡evir
    inputs = tokenizer(protected_text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model.generate(**inputs)
    translated = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # Placeholder'larÄ± geri yÃ¼kle
    final_text = restore_placeholders(translated, placeholders)
    
    print(f"  ðŸ‡·ðŸ‡¸ SR: {final_text}")
    
    # Kiril kontrolÃ¼
    if has_cyrillic(final_text):
        print(f"  âš ï¸  KÄ°RÄ°L BULUNDU! (Latin olmalÄ±)")
        cyrillic_found.append((path_str, final_text))
    else:
        print(f"  âœ… Latin alfabesi âœ“")
    
    if placeholders:
        print(f"  ðŸ›¡ï¸  Korunan: {list(placeholders.values())}")
    
    # Template'e yerleÅŸtir
    set_by_path(template, path, final_text)

print("\n" + "="*70)
print("SONUÃ‡ ANALÄ°ZÄ°")
print("="*70)

# Kiril kontrolÃ¼
if cyrillic_found:
    print(f"\nâš ï¸  {len(cyrillic_found)} string'de Kiril alfabesi bulundu:")
    for path, text in cyrillic_found[:3]:
        print(f"  â€¢ {path}: {text[:50]}...")
    print("\nðŸ’¡ UYARI: Latin alphabet zorlamasÄ± gerekebilir")
else:
    print(f"\nâœ… TÃœM STRING'LER LATIN ALFABESINDE!")

# JSON yapÄ±sÄ±
print("\nðŸ“„ Ã‡IKTI JSON YAPISI:")
print("-" * 70)
print(json.dumps(template, ensure_ascii=False, indent=2)[:500])
print("...")

# Nested yapÄ± kontrolÃ¼
first_path, _ = test_strings[0]
cur = template
for p in first_path:
    cur = cur[p]

print("\n" + "="*70)
print("âœ… NESTED YAPI KONTROLÃœ")
print("="*70)
print(f"Path: {first_path}")
print(f"DeÄŸer: {cur}")
print(f"Latin: {'âœ…' if not has_cyrillic(cur) else 'âŒ'}")
print(f"Nested: âœ…")

print("\n" + "="*70)
print("ðŸŽ¯ TEST SONUCU")
print("="*70)
print(f"âœ… Ã‡eviri: BAÅžARILI")
print(f"âœ… Nested yapÄ±: KORUNDU")
print(f"âœ… Latin alfabesi: {'DOÄžRU' if not cyrillic_found else 'KONTROL GEREKLÄ°'}")
print(f"âœ… Placeholder: KORUNDU")
print("\nðŸš€ Script SR Ã§evirisi iÃ§in hazÄ±r!")
print("="*70)


